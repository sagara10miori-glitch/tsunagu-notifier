import os
import re
import time
import datetime
import requests

from utils.fetch import parse_html, validate_image_url
from utils.storage import load_json, save_json, append_json_list, clear_json
from utils.hashgen import generate_item_hash
from utils.shorturl import get_short_url
from utils.discord import send_discord


# ============================
# è¨­å®š
# ============================

WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")

URL_EXIST = (
    "https://tsunagu.cloud/exist_products"
    "?sort=&exist_product_category_id=2"
    "&exist_product_category2_id=2"
    "&exist_product_category3_id="
    "&keyword=&max_sales_count_exist_items=1"
    "&is_selling=true&is_ai_content=0"
)

URL_AUCTION = (
    "https://tsunagu.cloud/auctions"
    "?sort=&exist_product_category_id=2"
    "&exist_product_category2_id=2"
    "&exist_product_category3_id="
    "&keyword=&is_disp_progress=1&is_ai_content=0"
)

DATA_LAST = "data/last_all.json"
DATA_SELLER = "data/seller_cache.json"
DATA_PENDING_EXIST = "data/pending_night_exist.json"
DATA_PENDING_AUCTION = "data/pending_night_auction.json"

def load_exclude_users(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return {line.strip() for line in f if line.strip() and not line.startswith("#")}
    except FileNotFoundError:
        return set()

EXCLUDE_USERS = load_exclude_users("config/exclude_users.txt")

# ============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================

def now():
    return datetime.datetime.now()

def is_night():
    return 2 <= now().hour < 6

def is_morning():
    return now().hour == 6 and now().minute == 0

def normalize_price(s):
    d = "".join(c for c in s if c.isdigit())
    return f"{int(d):,}å††" if d else "0å††"

def normalize_url(url):
    m = re.search(r"(auctions|exist_products)/(\d+)", url)
    return f"{m.group(1)}/{m.group(2)}" if m else url.split("?")[0].split("#")[0]

# ============================
# Cloudflare ã«å¼·ã„ HTML fetch
# ============================

def fetch_html(url):
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/121.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    }

    proxy = os.getenv("PROXY_URL")
    proxies = {"http": proxy, "https": proxy} if proxy else None

    for t in range(2):
        try:
            r = requests.get(url, headers=headers, proxies=proxies, timeout=5)
            r.raise_for_status()
            return r.text
        except Exception:
            time.sleep(1 + t)

    return ""


# ============================
# seller_id æŠ½å‡ºï¼ˆé«˜é€Ÿãƒ»å®‰å®šï¼‰
# ============================

seller_cache = {}

def fetch_seller_id(url):
    if url in seller_cache:
        return seller_cache[url]

    soup = parse_html(fetch_html(url))
    if not soup:
        seller_cache[url] = ""
        return ""

    # /users/ ã¾ãŸã¯ /profile/ ã‚’æ¢ã™
    for pat in ["/users/", "/profile/"]:
        for a in soup.find_all("a", href=True):
            href = a["href"]
            if pat in href:
                m = re.search(pat + r"([^/?#]+)", href)
                if m:
                    seller_cache[url] = m.group(1)
                    return seller_cache[url]

    seller_cache[url] = ""
    return ""


# ============================
# HTML è§£æï¼ˆèª¤æ¤œå‡ºã‚¼ãƒ­ï¼‰
# ============================

def parse_items(soup, mode):
    items = []

    for c in soup.find_all(class_="p-product"):
        # ã‚¿ã‚¤ãƒˆãƒ«
        t = c.find(class_="title")
        title = t.get_text(strip=True) if t else ""

        # ä¾¡æ ¼ï¼ˆtext-danger å„ªå…ˆï¼‰
        price_tag = c.find("p", class_=lambda x: x and "text-danger" in x)

        if not price_tag:
            # fallbackï¼ˆå†† or Â¥ ã‚’å«ã‚€æ•°å­—ã‚¿ã‚°ï¼‰
            for tag in c.find_all(["p", "h2", "h3"]):
                txt = tag.get_text(strip=True)
                if any(x in txt for x in ["å††", "Â¥"]) and any(ch.isdigit() for ch in txt):
                    price_tag = tag
                    break

        price = normalize_price(price_tag.get_text(strip=True) if price_tag else "")

        # å³æ±ºä¾¡æ ¼
        buy_now = None
        h2 = c.find("h2")
        if h2 and ("å³æ±º" in h2.text):
            buy_now = normalize_price(h2.text)

        # URL
        url = c.find("a")["href"]
        if url.startswith("/"):
            url = "https://tsunagu.cloud" + url

        # ã‚µãƒ ãƒã‚¤ãƒ«
        img_tag = c.find("img")
        thumb = img_tag["src"] if img_tag else ""

        items.append({
            "title": title,
            "price": price,
            "buy_now": buy_now,
            "thumb": thumb,
            "url": url,
            "mode": mode,
        })

    return items

# ============================
# embed ç”Ÿæˆï¼ˆçŸ­ããƒ»ç¾ã—ãï¼‰
# ============================

def build_embed(item):
    p = int(item["price"].replace("å††", "").replace(",", ""))
    color = 0xE74C3C if p <= 5000 else 0x3498DB if p <= 9999 else 0x2ECC71
    short = get_short_url(item["url"])

    fields = [
        {"name": "URL", "value": short, "inline": False},
        {
            "name": "è²©å£²å½¢å¼",
            "value": "æ—¢å­˜è²©å£²" if item["mode"] == "exist" else "ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³",
            "inline": True,
        },
        {"name": "ä¾¡æ ¼", "value": item["price"], "inline": True},
    ]

    if item["buy_now"]:
        fields.append({"name": "å³æ±ºä¾¡æ ¼", "value": item["buy_now"], "inline": True})

    embed = {
        "title": item["title"][:256],
        "url": short,
        "color": color,
        "fields": fields,
    }

    img = validate_image_url(item["thumb"])
    if img:
        embed["image"] = {"url": img}

    return embed


# ============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================

def main():
    global seller_cache

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿
    seller_cache = load_json(DATA_SELLER, default={})
    last = load_json(DATA_LAST, default={})

    # æœ6æ™‚ã¾ã¨ã‚é€šçŸ¥
    if is_morning():
        pending = load_json(DATA_PENDING_EXIST, []) + load_json(DATA_PENDING_AUCTION, [])
        if pending:
            send_discord(WEBHOOK_URL, "ğŸŒ… æ·±å¤œå¸¯ã¾ã¨ã‚é€šçŸ¥", pending[:10])
        clear_json(DATA_PENDING_EXIST)
        clear_json(DATA_PENDING_AUCTION)

    # HTMLå–å¾—
    soup_exist = parse_html(fetch_html(URL_EXIST))
    soup_auction = parse_html(fetch_html(URL_AUCTION))

    items = []
    if soup_exist:
        items += parse_items(soup_exist, "exist")
    if soup_auction:
        items += parse_items(soup_auction, "auction")

    # ä¾¡æ ¼ã®å®‰ã„é †ã«ä¸¦ã¹ã‚‹
    items.sort(key=lambda x: int(x["price"].replace("å††", "").replace(",", "")))

    embeds = []

    # ============================
    # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ãƒ»é€šçŸ¥åˆ¤å®šï¼‰
    # ============================

    for item in items:
        # URL æ­£è¦åŒ– â†’ ãƒãƒƒã‚·ãƒ¥åŒ–ï¼ˆé‡è¤‡é€šçŸ¥é˜²æ­¢ã®æ ¸ï¼‰
        key = normalize_url(item["url"])
        h = generate_item_hash(key)

        if h in last:
            continue

        # ä¾¡æ ¼ãƒ•ã‚£ãƒ«ã‚¿
        price = int(item["price"].replace("å††", "").replace(",", ""))
        if price >= 15000:
            last[h] = True
            continue

        # seller_id åˆ¤å®š
        seller = fetch_seller_id(item["url"])
        if not seller or seller in EXCLUDE_USERS:
            last[h] = True
            continue

        # æ·±å¤œå¸¯ â†’ pending ã«ä¿å­˜ã—ã¦é€šçŸ¥ã—ãªã„
        if is_night():
            path = DATA_PENDING_EXIST if item["mode"] == "exist" else DATA_PENDING_AUCTION
            append_json_list(path, item)
            last[h] = True
            continue

        # é€šå¸¸é€šçŸ¥ï¼ˆæœ€å¤§10ä»¶ï¼‰
        if len(embeds) < 10:
            embeds.append(build_embed(item))

        last[h] = True

    # ============================
    # é€šçŸ¥é€ä¿¡
    # ============================

    if embeds:
        first_price = int(
            embeds[0]["fields"][2]["value"].replace("å††", "").replace(",", "")
        )

        title = (
            "@everyone\nğŸ“¢ã¤ãªãã€€æ–°ç€é€šçŸ¥" if first_price <= 5000 else
            "ğŸ””ã¤ãªãã€€æ–°ç€é€šçŸ¥" if first_price <= 9999 else
            "ğŸ“ã¤ãªãã€€æ–°ç€é€šçŸ¥"
        )

        send_discord(WEBHOOK_URL, title, embeds)

    # ============================
    # ä¿å­˜ï¼ˆlast_all / seller_cacheï¼‰
    # ============================

    save_json(DATA_LAST, last)
    save_json(DATA_SELLER, seller_cache)


# ============================
# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ============================

if __name__ == "__main__":
    main()
